---
title: "Predictive Analysis of Bankruptcy"
subtitle: "Based on Financial Indicators"
author: "Group- V : Adrija Saha, Sampurna Mondal, Shrayan Roy"
institute: "Indian Statistical Institute (Delhi Centre)"
date: "12/04/2023"
header-includes:
  -\usepackage{bbm}
  -\usepackage{mathtools}
output:
  xaringan::moon_reader:
    lib_dir: libs
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---
class: center, top
background-image: url("hello.jpeg")
background-size: cover

#Statistical Analysis of Bankrupt firms 
## Based on Financial Indicators
#  
##Group- V: Adrija Saha, Sampurna Mondal, Shrayan Roy
## Date: 12/04/2023

---

# Data Description :

* The dataset considered here, is an Annual financial data of financially sound firms
and the firms which went bankrupt after two years.

--

* It contains 46 observations and 5
columns, where last column is the categorical response variable. Which is 0, if the firm went
.red[**bankrupt**] and 1, if the firm remains .green[**financially sound**].

* 21 observations on bankrupt firms and 25 observations on Financially Sound firms. 

--

* Rest of the four columns are explanatory variables. 

* The explanatory variables provided in this dataset are all continuous. Their names are given by - 

  1. **Ratios of cash flow to total debt (CFTD)**
  
  2. **Ratios of net income to total assets (NITA)**
  
  3. **Ratios of current assets to total liabilities (CATL)**
  
  4. **Ratios of current assets to net sales (CANS)**



```{css,echo = F}
.reduced_opacity {
  opacity: 0.4;
}
.red { color: red; }
.green { color: green; }
.blue { color: blue; }
.scroll-1000 {
  max-height: 400px;
  max-width: 1000px;
  overflow-y: auto;
  background-color: inherit;
}
```


---

# Let's have a look at our dataset 

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,echo=FALSE,warning=FALSE,fig.width=12,fig.height=6.3}

suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(lattice))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(Matrix))
suppressPackageStartupMessages(library(reshape2))
suppressPackageStartupMessages(library(ggside))
suppressPackageStartupMessages(library(tidyquant))
suppressPackageStartupMessages(library(wesanderson))
suppressPackageStartupMessages(library(aplpack))
suppressPackageStartupMessages(library(GGally))
suppressPackageStartupMessages(library(biotools))
suppressPackageStartupMessages(library(kableExtra))

setwd("C:/Users/Adrija Saha/Desktop/Multivariate Analysis")

```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
My.data <- read.table("bankruptcy.txt")
colnames(My.data) <- c("CFTD","NITA","CATL","CANS","y")
library(DT)
DT::datatable(My.data,
  fillContainer = FALSE, options = list(pageLength = 10))
```

---

# Understanding the meaning of Explanatory variables :

.pull-left[

### • Ratios of cash flow to total debt:
 
This ratio is a type of coverage ratio and can be used to determine how long it would take a company to repay its debt if it devoted all of its cash flow to debt repayment. .red[More the value of the ratio more financially stable it is.]



### • Ratios of net income to total assets:

It refers to a financial ratio that indicates how profitable a company is in relation to its total assets. .red[A higher ROA means a company is more efficient.]

]

.pull-right[

### • Ratios of current assets to total liabilities:

This ratio measures a company’s ability to pay short-term obligations or those due within one year with its total assets.Hence, .red[higher value of this ratio indicates less probable of being bankrupt.]



### • Ratios of current assets to net sales:

This ratio has an inverse relation with current assets turnover.A higher asset turnover ratio means a better percentage of sales.The .red[less the amount of current assets-net sales ratio, the better the ability of the company to generate sales.]

]


---

class: inverse,middle, center

background-image: url("eda_finalcover.png")
background-size: cover

# Exploratory 
# Data Analysis

##(EDA)



---


## Exploratory Data Analysis: Scatterplot  
```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=7.5,message=FALSE}

defined_theme <- theme(plot.subtitle = element_text(family = "mono",size = 11,
                                                    face = "bold",hjust = 0.01),axis.title = element_text(family = "serif"),
                       axis.text = element_text(size = 10),plot.title = element_text(family = "serif",
                      colour = "red", hjust = -0.01),legend.text = element_text(size = 10,family = "serif"), 
                       legend.title = element_text(family = "serif"),legend.background = element_blank(),
                       legend.box.background = element_rect(colour = "black")) + 
    theme(strip.background = element_rect(fill = "#FFE5B4")) 

My.data0 <- My.data[My.data$y == 0,]  #Data for Bankrupt #Firms
My.data1 <- My.data[My.data$y == 1,]  #Data for Not #Bankrupt Firms

#===============================================================================================

graph.data <- as.data.frame(cbind(melt(My.data[,-5]),y = My.data$y,Index = ifelse(My.data$y == 0,"Bankrupt","Non-Bankrupt")))
graph.data0 <- as.data.frame(cbind(melt(My.data0[,-5])))
graph.data1 <- as.data.frame(cbind(melt(My.data1[,-5])))
Index <- ifelse(My.data$y == 0,"Bankrupt","Non-Bankrupt")


#y vs. Covariates
ggplot(graph.data,aes(y = y,x = value,col = variable)) + geom_point(size = 2.7) + 
  geom_smooth(se = FALSE, size = 2) + scale_y_discrete(limits = c(0,1)) + 
  labs(x = "",y = "Bankruptcy Status",title = "Scatterplot of y vs. Covarites") + 
  facet_wrap(.~variable,scales = "free")+ theme(axis.title = element_text(size=30)) + 
  theme_bw(14) + defined_theme 


```

---

## Exploratory Data Analysis: Boxplot

```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=7.5,message=FALSE}

ggplot(graph.data,aes(x = value)) + geom_boxplot(aes(fill = Index),outlier.shape = 4,alpha = 0.7,
                                                 outlier.colour = "red",outlier.size = 2,outlier.stroke = 1.5) + 
  facet_wrap(.~variable,scales = "free") + labs(y = "",title = "BoxPlot of Co-variates of Bankruptcy Data") + 
  theme_bw(14) + defined_theme +   scale_fill_manual(values = c("hotpink","skyblue1"))
  
```

---
## Exploratory Data Analysis: Pairwise Comparison

```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=7.5,message=FALSE}
ggpairs(My.data[,-5], 
        mapping = ggplot2::aes(color = factor(My.data[,5])),
        lower = list(continuous = wrap("points",size = 2.5)),
        diag = list(continuous = wrap("barDiag", bins = 10,alpha = 0.7,position = "identity",col = "black")),
        upper = list(continuous = wrap("cor",size = 6.5) )) +
  theme_bw(14) + defined_theme + scale_color_manual(values = c("hotpink","deepskyblue3")) + 
  scale_fill_manual(values = c("hotpink","skyblue1")) 


```
---

## Exploratory Data Analysis: Pairwise Comparison

```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=7.5,message=FALSE}
ggpairs(My.data[,-5], 
        mapping = ggplot2::aes(color = factor(My.data[,5])),
        lower = list(continuous = wrap("points",size = 2.5)),
        diag = list(continuous = wrap("densityDiag",alpha = 0.7)),
        upper = list(continuous = wrap("cor",size = 6.5) )) +
  theme_bw(14) + defined_theme + scale_color_manual(values = c("hotpink","deepskyblue3")) + 
  scale_fill_manual(values = c("hotpink","skyblue1")) 

```

---

## Exploratory Data Analysis: Correlation Plot
* For Bankrupt Firms
```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=6.5,message=FALSE}

corrplot::corrplot(cor(My.data0[,-5]))
```
---

## Exploratory Data Analysis: Correlation Plot
* For Financial sound Firms
```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=6.5,message=FALSE}
corrplot::corrplot(cor(My.data1[,-5]))

```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

---

# Checking Normality in Bankrupt Firms:

.panelset[
.panel[.panel-name[Q-Q Plot]

```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=6.5,message=FALSE}

#qqplot
par(mfrow = c(2,2))

#Bankrupt
qqPlot(My.data0$CFTD,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CFTD",
       main = "QQ Plot of CFTD",col = "red",pch = 19,id=F)
qqPlot(My.data0$NITA,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of NITA",
       main = "QQ Plot of NITA",col = "red",pch = 19,id=F)
qqPlot(My.data0$CATL,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CATL",
       main = "QQ Plot of CATL",col = "red",pch = 19,id=F)
qqPlot(My.data0$CANS,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CANS",
       main = "QQ Plot of CANS",col = "red",pch = 19,id=F)

```
]

.panel[.panel-name[Shapiro Wilk Test]

```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=5,message=FALSE}
my.var=noquote(c("CFTD","NITA","CATL","CANS"))
test.stat=c(0.95817,0.91084,0.95948,0.93724)
p.val=c(0.48,0.05706,0.5057,0.1921)
my.dec=noquote(c("Accept","Accept","Accept","Accept"))
my.table=data.frame(test.stat,p.val,my.dec)
rownames(my.table)=my.var
colnames(my.table) <- c("Value of Test Statistic","p-Value","Decision")
knitr::kable(as.data.frame(my.table),format="html")

```
]
]


---
# Checking Normality in Financially sound Firms:
.panelset[
.panel[.panel-name[Q-Q Plot]
```{r,echo=FALSE,warning =FALSE,fig.width=14,fig.height=6.5,message=FALSE}
par(mfrow = c(2,2))
#Non-Bankrupt
qqPlot(My.data1$CFTD,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CFTD",
       main = "QQ Plot of CFTD",pch = 19,id=F)
qqPlot(My.data1$NITA,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of NITA",
       main = "QQ Plot of NITA",pch = 19,id=F)
qqPlot(My.data1$CATL,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CATL",
       main = "QQ Plot of CATL",pch = 19,id=F)
qqPlot(My.data1$CANS,xlab = "Normal(0,1) Quantiles",ylab = "Observed Quantiles of CANS",
       main = "QQ Plot of CANS",pch = 19,id=F)

```
]
.panel[.panel-name[Shapiro Wilk Test]

```{r,echo=FALSE,warning =TRUE,fig.width=14,fig.height=5,message=FALSE}

my.var=noquote(c("CFTD","NITA","CATL","CANS"))
test.stat=c(0.9417,0.92382,0.90742,0.96139)
p.val=c(0.162,0.06265,0.02671,0.4429)
my.dec=noquote(c("Accept","Accept","Reject","Accept"))
my.table=data.frame(test.stat,p.val,my.dec)
rownames(my.table)=my.var
colnames(my.table) <- c("Value of Test Statistic","p-Value","Decision")
my.table%>% kbl %>% kable_paper(full_width = F) %>% row_spec(3, color = 'red',bold = T,italic=T)
```
]
]
---
# Chi-Square Plot for checking Multivariate Normality
```{r,echo=FALSE,warning =TRUE,fig.width=14,fig.height=5,message=FALSE}

md.1 <- mahalanobis(My.data0[,-5],colMeans(My.data0[,-5]),cov(My.data0[,-5]))
md.2 <- mahalanobis(My.data1[,-5],colMeans(My.data1[,-5]),cov(My.data1[,-5]))

par(mfrow = c(1,2))
qqPlot(md.1,"chisq",df = 4,main = "QQ Plot of Sqaured Mahalanobis Distance for Bankrupt Firms",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",xlab = "Chisquare(4) Quantiles",id=F)

qqPlot(md.2,"chisq",df = 4,main = "QQ Plot of Sqaured Mahalanobis Distance for Non-Bankrupt Firms",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",xlab = "Chisquare(4) Quantiles",id=F)
```

---

#Royston Test : A test of Multivariate Normality :

* Royston’s test uses the Shapiro-Wilk/Shapiro-Francia statistic to test multivariate normality. If kurtosis
of the data is greater than 3, then it uses the Shapiro-Francia test for leptokurtic distributions, otherwise it uses the Shapiro-Wilk test for platykurtic distributions.

* It's implementation is available in .green[**MVN**] package .red[**R**].

* For more details see [MVN: An R Package for Assessing
Multivariate Normality](https://journal.r-project.org/archive/2014-2/korkmaz-goksuluk-zararsiz.pdf)

---

# Test for Multivariate Normality : Royston Test (Bankrupt Firms):

.pull-left[
```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=6.5,message=FALSE}
r1 <- MVN::mvn(data = My.data0[,-5], mvnTest = "royston",univariateTest = "SW",
               desc = FALSE,showOutliers = TRUE,multivariateOutlierMethod = "adj")
```
]

.pull-right[
```{r,eval = FALSE,warning =TRUE,fig.width=7,fig.height=6.5,message=FALSE,}
MVN::mvn(data = My.data0[,-5], mvnTest = "royston",univariateTest = "SW",
         desc = FALSE,showOutliers = TRUE,multivariateOutlierMethod = "adj")
```

```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=4.5,message=FALSE}
r1$multivariateNormality
r1$multivariateOutliers
```
]


---

# Test for Multivariate Normality : Royston Test (Financial Sound Firms):

.pull-left[
```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=6.5,message=FALSE}
r2 <- MVN::mvn(data = My.data1[,-5], mvnTest = "royston",univariateTest = "SW",
         desc = FALSE,showOutliers = TRUE,multivariateOutlierMethod = "adj")
```
]

.pull-right[

```{r,eval = FALSE,warning =TRUE,fig.width=7,fig.height=5,message=FALSE}
MVN::mvn(data = My.data1[,-5], mvnTest = "royston",univariateTest = "SW",
         desc = FALSE,showOutliers = TRUE,multivariateOutlierMethod = "adj")
```

```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=4.5,message=FALSE}
r2$multivariateNormality
r2$multivariateOutliers
```
]

---

# A short Note on Robust Mahalanobis Distance :

* Classical Mahalanobis distance is used as a method of detecting outliers.

--

* But it involves estimate of mean vector and variance-covariance matrix.So, affected by outliers !

--

* So, a robust method is used to find estimate of mean vector and variance-covariance matrix. Depending upon choice of estimator, we will get different Robust Mahalanobis Distance


* **R** uses adjusted quantile method based Mahalanobis Distance.

--

* For more details : [Selcuk Korkmaz, Dincer Goksuluk and Gokmen Zararsiz :   MVN: An R Package for Assessing Multivariate Normality](https://journal.r-project.org/archive/2014-2/korkmaz-goksuluk-zararsiz.pdf)


---
class: center, middle
background-image: url("da_cover.png")
background-size: cover
 
# Discriminant Analysis 
---
# Checking Multivariate Normality dropping variables :

.center[* Two Variables at a time ! ]

.panelset[
.panel[.panel-name[Royston Test]
.pull-bottom[.green[Here only we will not include CATL anywhere.Since, taking CATL disturbs univariate normality in 2nd population.]]
.pull-left[

## For Bankrupt firms

```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=4.5,message=FALSE}
table.1=noquote(c("CFTD,NITA","CFTD,NITA","CFTD,CANS",
                  "CFTD,CANS","NITA,CANS","NITA,CANS"))
table.2=noquote(c("Bankrupt","Finanical Sound",
                  "Bankrupt","Finanical Sound",
                  "Bankrupt","Finanical Sound"))
table.3=c(3.151806,6.122089,2.737765,2.735482,5.322533,5.146921)
table.4=c(0.1168098,0.03925884,0.2543941,0.2545416,0.0698239,0.07627114)
table.5=noquote(c("Accept","Reject","Accept","Accept","Accept","Accept"))
my.table=data.frame(table.1,table.2,
                    table.3,table.4,table.5)
colnames(my.table)=c("Variables Included","Firm Type",
                     "Test statistic","p-Value","Decision")
table.bankrupt=my.table[c(1,3,5),-2]
table.bankrupt%>% kbl %>% kable_paper(full_width = F) %>% row_spec(c(2,3), color = c('green','green'),bold = T,italic=T)
table.nonbankrupt=my.table[c(2,4,6),-2]
```
]

.pull-right[

## For Financially sound firms

```{r,echo=FALSE,warning =TRUE,fig.width=7,fig.height=4.5,message=FALSE}
table.nonbankrupt%>% kbl %>% kable_paper(full_width = F) %>% row_spec(c(2,3), color = c('green','green'),bold = T,italic=T)
```

]

]

.panel[.panel-name[Chi-Square Plots for CFTD & CANS]

```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
md.1 <- mahalanobis(My.data[My.data$y == 0,-c(3,2,5)],colMeans(My.data[My.data$y == 0,-c(3,2,5)]),
                     cov(My.data[My.data$y == 0,-c(3,2,5)]))
md.2 <- mahalanobis(My.data[My.data$y == 1,-c(3,2,5)],colMeans(My.data[My.data$y == 1,-c(3,2,5)]),
                     cov(My.data[My.data$y == 1,-c(3,2,5)]))

#QQ Plot of Sqaured Mahalanobis Distance

par(mfrow = c(1,2))
qqPlot(md.1,"chisq",df = 2,main = "Bankrupt Firms With CFTD & CANS ",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",id = F)
qqPlot(md.2,"chisq",df = 2,main = "Non-Bankrupt Firms With CFTD & CANS",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",id = F)
```

]

.panel[.panel-name[Chi-Square Plots for NITA & CANS]

```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
md.3 <- mahalanobis(My.data[My.data$y == 0,-c(1,3,5)],colMeans(My.data[My.data$y == 0,-c(1,3,5)]),
                     cov(My.data[My.data$y == 0,-c(1,3,5)]))
md.4 <- mahalanobis(My.data[My.data$y == 1,-c(1,3,5)],colMeans(My.data[My.data$y == 1,-c(1,3,5)]),
                     cov(My.data[My.data$y == 1,-c(1,3,5)]))

par(mfrow = c(1,2))
qqPlot(md.3,"chisq",df = 2,main = "Bankrupt Firms With  NITA & CANS",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",id = F)
qqPlot(md.4,"chisq",df = 2,main = "Non-Bankrupt Firms With  NITA & CANS",
       pch = 19,col = 'red',ylab = "Mahalanobis Distance",id=F)
```

]
]

---

# Analysis with CFTD & CANS :

.panelset[
.panel[.panel-name[ .red[Box-M Test and MANOVA]]

.pull-top[

```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data[,-c(2,3,5)]) ~ as.factor(y),data = My.data)
```
]

.pull-bottom[

```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
model.manova <- manova(cbind(CFTD,CANS)~y,data = My.data)
summary(model.manova)
```
]

]

.panel[.panel-name[ .red[LDA]]

.pull-left[

```{r}
lda(My.data[,-c(2,3,5)],My.data$y)
```
]

.pull-right[

```{r,echo=F,warning =TRUE,fig.width=6.7,fig.height=6.2,message=FALSE}

Lda_Model.1 <- lda(My.data[,-c(2,3,5)],My.data$y,CV = T)

Lda_Model.1_scores.df <- data.frame(Scores = as.matrix(My.data[,-c(2,3,5)])%*%as.vector(lda(My.data[,-c(2,3,5)],My.data$y)$scaling),
                                    y = My.data$y)

ggplot(Lda_Model.1_scores.df,aes(y = jitter(rep(1,46)),x = Scores,col = Index)) + geom_point(size = 3) + 
  labs(y = "",x = "Plot of LDA Score",title = "LDA Scores") + theme_bw(14)+ defined_theme + ylim(0.95,1.05)
  
```

]

]

.panel[.panel-name[ .red[Performance]]

.pull-left[
```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

klaR::partimat(as.factor(y) ~., method = "lda",data =My.data[,-c(2,3)])

```
]

.pull-right[

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data[,5], Predicted = predict(lda(My.data[,-c(2,3,5)],My.data$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], Lda_Model.1$class)

```

]

]

]

---

# Analysis with NITA & CANS:
.panelset[
.panel[.panel-name[ .red[Box-M Test]]


```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data[,-c(1,3,5)]) ~ as.factor(y),data = My.data)

```

]

.panel[.panel-name[ .red[QDA]]


```{r}
qda(My.data[,-c(1,3,5)],My.data$y)
```

]

.panel[.panel-name[ .red[Performance]]

.pull-left[
```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
Qda_Model.2 <- MASS::qda(My.data[,-c(1,3,5)],My.data$y,CV = T)
klaR::partimat(as.factor(y) ~., method = "qda",data =My.data[,-c(1,3)])

```
]

.pull-right[

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data[,5], Predicted = predict(qda(My.data[,-c(1,3,5)],My.data$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], Qda_Model.2$class)

```

]

]

]

---
# Checking Multivariate Normality dropping variables :

* Three Variables at a time! 


.panelset[
.panel[.panel-name[Royston Test]
.pull-bottom[.green[Here only we will check dropping CATL.Since, taking CATL disturbs univariate normality in 2nd population.]]
* For Bankrupt Firms
```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
MVN::mvn(My.data[My.data$y == 0,-c(3,5)],mvnTest = "royston")$multivariateNormality
```

* For Financial sound Firms
```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
MVN::mvn(My.data[My.data$y == 0,-c(3,5)],mvnTest = "royston")$multivariateNormality
```

]


.panel[.panel-name[Chi-Square Plot for CFTD,NITA & CANS]
```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=5.5,message=FALSE,fig.align='center'}
md.5 <- mahalanobis(My.data[My.data$y == 0,-c(3,5)],colMeans(My.data[My.data$y == 0,-c(3,5)]),
                    cov(My.data[My.data$y == 0,-c(3,5)]))
md.6 <- mahalanobis(My.data[My.data$y == 1,-c(3,5)],colMeans(My.data[My.data$y == 1,-c(3,5)]),
                    cov(My.data[My.data$y == 1,-c(3,5)]))

par(mfrow = c(1,2))
qqPlot(md.5,"chisq",df = 3,main = "Bankrupt Firms  With CFTD,NITA,CANS",
       pch = 19,col = 'red',ylab = "Sqaured Mahalanobis Distance",id=F)
qqPlot(md.6,"chisq",df = 3,main = "Non-Bankrupt Firms With CFTD,NITA,CANS",
       pch = 19,col = 'red',ylab = "Sqaured Mahalanobis Distance",id=F)

```
]
]

---

# Analysis with CFTD, NITA & CANS:
.panelset[
.panel[.panel-name[ .red[Box-M Test]]


```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data[,-c(3,5)]) ~ as.factor(y),data = My.data)

```

]

.panel[.panel-name[ .red[QDA]]


```{r}
qda(My.data[,-c(3,5)],My.data$y)
```

]

.panel[.panel-name[ .red[Performance]]


.red[Training Set Performance]
```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

Qda_Model.3 <- MASS::qda(My.data[,-c(3,5)],My.data$y,CV = T)
```

```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
table(Actual = My.data[,5], Predicted = predict(lda(My.data[,-c(3,5)],My.data$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], Qda_Model.3$class)

```

]

]

---

#Transformation for Multivariate Normality :

* **Box-Cox Transformation** is a commonly used transformation for normality.

--

* But, Applicability of this is restricted to positive valued variables only.

--

* [Yeo-Johnson :A New Family of Power Transformations to Improve Normality or Symmetry](https://www.jstor.org/stable/2673623) suggested a generalized Box-cox transformation. Which is defined as - 

$$\psi(y,\lambda)=\begin{cases}\frac{(y+1)^\lambda - 1}{\lambda},& y\ge0,\lambda\not=0\\log(y+1),& y\ge0,\lambda=0\\-\frac{(-y+1)^{2-\lambda}-1}{2-\lambda},&y<0,\lambda\not=2\\-log(-y+1),&y<0,\lambda=2\end{cases}$$

* We will use this to transformation to achieve normality of third variable. 

* To obtain Optimal $\lambda$, we will use likelihood based approach. 


---
# Transforming CATL for Financially sound firms:

```{r,echo = F}

par(mfrow = c(1,1))
#For univariate normality ! 

gbc <- function(x,lambda){
  if(lambda != 0 & x >= 0){
    s = ((x+1)^lambda - 1)/lambda
  }else if(x >= 0 & lambda == 0){
    s = log(x+1)  
  }else if( x < 0 & lambda != 2){
    s = -((-x + 1)^(2 - lambda) - 1)/(2 - lambda)
  }else if( x < 0 &  lambda == 2){
    s = - log( - x + 1)
  }
  return(s)
}

#Likelihood boxcox

l.gbc <- function(data,lambda.0){
  n <- length(data)
  transformed.data <- vapply(data, FUN = function(x){gbc(x,lambda.0)}, FUN.VALUE = 2)
  mu.est <- mean(transformed.data)
  sigma.sq.est <- var(transformed.data)*(n-1)/n
  
  a <- (-n/2)*log(2*pi) - (n/2)*log(sigma.sq.est) - (1/(2*sigma.sq.est))*sum((transformed.data - mu.est)^2) 
  b <- (lambda.0 - 1)*sum(sign(data)*log(abs(data) + 1))
  
  return(a + b)
}

g.boxcox0 <- function(data0,lambda.seq){
  
  lbc.mv <- function(lambda.1){
    l.gbc(data0,lambda.1)  
  }
  
  plot(lambda.seq,vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2),
       col = "red",type = "l",xlab = "Lambda",ylab = "Log Likelihood",
       main = "Plot of Log Likelihood vs. Lambda",lwd = 3)
  abline(h = max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2)) - 0.5,lty = 2,col = "blue",lwd = 2)
  abline(v = lambda.seq[which.max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))],lty = 2,col = "blue",lwd = 2)
  print(c("Optimal Lambda" = lambda.seq[which.max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))],
          "Likelihood Value" = max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))))
  
}


```
.panelset[
.panel[.panel-name[ Finding Optimum lambda ]


```{r,echo = F,warning =TRUE,fig.width=6,fig.height=4.5,message=FALSE,fig.align='center'}
g.boxcox0(My.data1[,3],seq(-10,10,by = 0.01))

```

]

.panel[.panel-name[Test for Multivariate Normality]

* After transformation:

```{r,echo = F}
My.data_trans0 <- My.data
My.data_trans0[,3] <- yjPower(My.data[,3],0.41)
```

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(data = My.data_trans0[My.data_trans0$y == 1,-5], mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.red[Multivariate Normality Rejected ! ]

]
]

---
# Finding Optimum $\lambda$ based on joint likelihood:


---
# Transforming CATL maximing joint likelihood:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
g.boxcox<- function(data0,data1,lambda.seq){
  
  #used to calculate joint likelihood 
  lbc.mv <- function(lambda.1){
  l.gbc(data0,lambda.1)+l.gbc(data1,lambda.1)
  #l.gbc calculates likelihood based on Yeo-Johnson
  }
  
  #plot of likelihood vs. lambda graph...
  plot(lambda.seq,vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2),
       col = "red",type = "l",xlab = "Lambda",ylab = "Log Likelihood",
       main = "Plot of Log Likelihood vs. Lambda",lwd = 3)
  
  #adding reference line...
  abline(h = max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2)) - 0.5,lty = 2,col = "blue",lwd = 2)
  abline(v = lambda.seq[which.max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))],lty = 2,col = "blue",lwd = 2)
  
  #Printing the value of optimal lambda...
print(c("Optimal Lambda" = lambda.seq[which.max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))],
          "Likelihood Value" = max(vapply(lambda.seq, FUN = lbc.mv, FUN.VALUE = 2))))
  
}


```

---

# Transforming CATL by maximizing joint likelihood:

.panelset[
.panel[.panel-name[ Finding Optimum lambda ]


```{r,echo = F,warning =TRUE,fig.width=6,fig.height=4.5,message=FALSE,fig.align='center'}
g.boxcox(My.data0[,3],My.data1[,3],seq(-10,10,by = 0.01))

```

]

.panel[.panel-name[For Bankrupt Firms]

* After transformation:

```{r,echo = F}
My.data_trans2 <- My.data
My.data_trans2[,3] <- yjPower(My.data[,3],0.72)
```

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(data = My.data_trans2[My.data_trans2$y == 0,-5], mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.green[Multivariate Normality Accepted ! ]

]
.panel[.panel-name[For Financially sound Firms]
* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(data = My.data_trans2[My.data_trans2$y == 1,-5], mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.red[Multivariate Normality Rejected ! ]
]
]

---

# Multivariate version of Yeo-Johnson family of Transformation:

* Univariate transformation is not helping much !

--

* .green[**Solution**]: Multivariate version of **Yeo-Johnson Transformation**. 

--

* Implementation is available in **R**, .green[**powerTransform**] function of .red[car] package.

--

* Let's try to implement this transformation on Financially Sound Firms first. 


---

# Using Multivariate Yeo-Johnson transformation :

.panelset[
.panel[.panel-name[ Finding Optimum lambda ]


```{r,echo = T,warning =TRUE,fig.width=6,fig.height=4.5,message=FALSE,fig.align='center'}

lambda.2 <- car::powerTransform(as.matrix(My.data1[,-5]),family = "yjPower")
lambda.2

```

```{r,echo = F}
My.data_trans4 <- as.data.frame(cbind(yjPower(with(My.data,cbind(CFTD,NITA,CATL,CANS)),coef(lambda.2)),y = My.data$y))
colnames(My.data_trans4) <- c(paste(colnames(My.data)[1:4],"Trans",sep = "_"),"y")

```

]

.panel[.panel-name[For Bankrupt Firms]

* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(data = My.data_trans4[My.data_trans4$y == 0,-5], mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.green[Multivariate Normality Accepted ! ]

]
.panel[.panel-name[For Financially sound Firms]
* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(data = My.data_trans4[My.data_trans4$y == 1,-5], mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.green[Multivariate Normality Accepted ! ]
]

.panel[.panel-name[Chisqaure Plot]

```{r,echo = F,warning =TRUE,fig.width=10,fig.height=6.5,message=FALSE,fig.align='center'}
#Let's check for Multivariate Normality using chi-square plot
md.7 <- mahalanobis(My.data_trans4[My.data_trans4$y == 0,-5],colMeans(My.data_trans4[My.data_trans4$y == 0,-5]),
                    cov(My.data_trans4[My.data_trans4$y == 0,-5]))
md.8 <- mahalanobis(My.data_trans4[My.data_trans4$y == 1,-5],colMeans(My.data_trans4[My.data_trans4$y == 1,-5]),
                    cov(My.data_trans4[My.data_trans4$y == 1,-5]))

#QQ Plot of Sqaured Mahalanobis Distance for 
par(mfrow = c(1,2))
qqPlot(md.7,"chisq",df = 4,main = "Bankrupt Firms - Transformed Data",
       pch = 19,col = 'red',ylab = "Sqaured Mahalanobis Distance",id = F)
qqPlot(md.8,"chisq",df = 4,main = "Non-Bankrupt Firms - Transformed Data",
       pch = 19,col = 'red',ylab = "Sqaured Mahalanobis Distance",id = F)
par(mfrow = c(1,1))
```
]

]

---

# Analysis Using All Transformed Variables:

.panelset[
.panel[.panel-name[ .red[Box-M Test]]


```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data_trans4[,-5]) ~ as.factor(y),data = My.data_trans4)

```

]

.panel[.panel-name[ .red[QDA]]


```{r}
qda(My.data_trans4[,-5],My.data_trans4$y)
```

]

.panel[.panel-name[ .red[Performance]]

```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
Qda_Model.4 <- MASS::qda(My.data_trans4[,-c(5)],My.data_trans4$y,CV = T)

```

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data[,5], Predicted = predict(qda(My.data_trans4[,-5],My.data_trans4$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], Qda_Model.4$class)

```

.green[**Less than the all previous models !**]

]



]

---
# Is their any better possible classifier with less variables :

* Less number of variables in a model is always good!


--

* Unless and until we are sacrificing much on misclassification error rate.


--

* Already discussed some discriminant rules after dropping variables.

--

* Now, let us see after transformation how are the performances of some other rules.

--

* Here, we will judge based on Leave-one out cross-validation apparent error rate. 


--

* First, let's drop one Variable at a time! 



---

# Transforming CFTD,NITA,CATL :

.panelset[
.panel[.panel-name[ Finding Optimum lambda ]


```{r,echo = T,warning =TRUE,fig.width=6,fig.height=4.5,message=FALSE,fig.align='center'}

lambda.6 <- car::powerTransform(as.matrix(My.data1[,-c(4,5)]),family = "yjPower")
lambda.6

```

```{r,echo = F}

My.data_trans6 <- My.data
My.data_trans6[,c(1,2,3)] <- with(My.data_trans6,yjPower(cbind(CFTD,NITA,CATL),coef(lambda.6)))


```

]

.panel[.panel-name[For Bankrupt Firms]

* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(with(My.data[My.data$y == 0,],yjPower(cbind(CFTD,NITA,CATL),coef(lambda.6))), mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.green[Multivariate Normality Accepted ! ]

]
.panel[.panel-name[For Financially sound Firms]
* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(with(My.data[My.data$y == 1,],yjPower(cbind(CFTD,NITA,CATL),coef(lambda.6))), mvnTest = "royston",
         univariateTest = "SW", desc = FALSE)
```

.green[Multivariate Normality Accepted ! ]
]

]

---

#Analysis taking CFTD, NITA, CATL(after transformation) :

.panelset[
.panel[.panel-name[ .red[Box-M Test]]


```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data_trans6[,c(1,2,3)]) ~ as.factor(y),data = My.data_trans6)
```

]

.panel[.panel-name[ .red[QDA]]


```{r}
qda(My.data_trans6[,c(1,2,3)], My.data_trans6[,5])
```

]

.panel[.panel-name[ .red[Performance]]

```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
Qda_Model.6 <- MASS::qda(My.data_trans6[,c(1,2,3)], My.data_trans6[,5], CV = T)

```

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data_trans6[,5], Predicted = predict(qda(My.data_trans6[,c(1,2,3)], My.data_trans6[,5]))$class)

```

.red[AER Estimate (Cross Validated)]

```{r}

aer(My.data[,5], Qda_Model.6$class)

```

.green[**Same as taking all four variables !**]

]

]

---

# Transforming CFTD,CATL,CANS:

.red[To bring multivariate normality, we will use optimum]  $\lambda$ =0.72 
.red[for transforming CATL.]

.panelset[
.panel[.panel-name[For Bankrupt Firms]

* After transformation:

```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(My.data_trans2[My.data_trans2$y == 0,-c(2,5)],mvnTest = "royston",univariateTest = "SW", 
         desc = F)
```

.green[Multivariate Normality Accepted ! ]

]
.panel[.panel-name[For Financially sound Firms]
* After transformation:


```{r,echo = T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
MVN::mvn(My.data_trans2[My.data_trans2$y == 1,-c(2,5)],mvnTest = "royston",univariateTest = "SW", 
         desc = F)
```

.green[Multivariate Normality Accepted ! ]
]

]

---

#Analysis taking CFTD, CATL, CANS(after transformation) :

.panelset[
.panel[.panel-name[ .red[Box-M Test]]


```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
heplots::boxM(as.matrix(My.data_trans2[,-c(2,5)]) ~ as.factor(y),data = My.data_trans2)
```

]

.panel[.panel-name[ .red[QDA]]


```{r,echo=T}
qda(My.data_trans2[,-c(2,5)],My.data_trans2$y)
```

]

.panel[.panel-name[ .red[Performance]]

```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
Qda_Model.7 <- MASS::qda(My.data_trans2[,-c(2,5)],My.data_trans2$y,CV = T)

```

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data_trans2[,5], Predicted = predict(qda(My.data_trans2[,-c(2,5)],My.data_trans2$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data_trans2[,5], Qda_Model.7$class)

```

.green[**Even, Better than including all four transformed variables !**]

]

]

---

#Results of other case :

* When we tried to transform NITA, CATL, CANS, neither Univariate nor Multivariate transformations help!

** Table of results of taking 2 variables at a time:**
(Which were not discussed previously)

```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

col.1=noquote(c("CFTD & NITA","CFTD & CATL","NITA & CATL","CATL & CANS"))
col.2=noquote(c("Multivariate","Not possible","Multivariate","Univariate"))
col.3=c(0.001785,NA,0.01501,0.002709)
col.4=c(0.2391304,NA,0.1304348,0.1521739)
result.table=data.frame(col.1,col.2,col.3,col.4)  
colnames(result.table)=c("Subsets","Transformation","Box-M p-Value",
                         "QDA CV AER estimate")
knitr::kable(result.table,format="html")
```

.red[Only transformed NITA & transformed CATL is producing the lowest estimate of AER amongst all!]

.green[Optimum] $\lambda$
.green[ for this transformation is ]
```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
powerTransform(My.data[My.data$y==1,c(2,3)],family="yjPower")
```
---

# Analysis Using Transformed NITA and Transformed CATL: 

.pull-left[

```{r,echo=FALSE}
lambda.51 <- powerTransform(My.data[My.data$y == 1,c(2,3)],family = "yjPower")
My.data_trans51 <- My.data
My.data_trans51[,c(2,3)] <- with(My.data,yjPower(cbind(NITA,CATL),coef(lambda.51)))
```


```{r,echo=TRUE}

qda(My.data_trans51[,c(2,3)], My.data_trans51[,5])

```
]

.pull-right[

```{r,echo=F,fig.height=7,fig.width=7}

klaR::partimat(as.factor(y) ~., method = "qda",data = My.data_trans51[,c(2,3,5)])

```
]

---

# Principal Component Analysis :

.panelset[
.panel[.panel-name[ .red[PCA]]

.pull-left[
```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
color <- ifelse(My.data[,5] == 0, "deeppink1", "deepskyblue3")
```

```{r,echo=TRUE,warning =TRUE,fig.width=10,fig.height=6,message=FALSE,fig.align='center'}
pca <- prcomp(My.data[,-5],scale = T)
pca
```
]
.pull-right[

```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=8,message=FALSE,fig.align='center'}
biplot(pca,main="BiPlot")


```

]

]


.panel[.panel-name[ .red[Plots]]

.pull-left[
```{r,echo=FALSE,warning =TRUE,fig.width=10,fig.height=8.5,message=FALSE,fig.align='center'}
data_pca <- as.data.frame(cbind(pca$x, My.data[,5]))
colnames(data_pca) <- c("PC1", "PC2", "PC3", "PC4", "y")
data_pca[,5] <- ifelse(data_pca[,5] == 1, "Bankrupt", "Non Bankrupt")
data_pca[,5] <- as.factor(data_pca[,5])
s = pca$sdev^2
plot(1:4,cumsum(s)/sum(s),type = "o",main = "Proportion of Variablity Explained by PC's",
     col = "red",pch= 19,lwd = 3,xlab = "Index",ylab = "Proportion")
points(1:4,cumsum(s)/sum(s),col = "blue",pch =19,cex = 2)
mtext(paste("Cumulative Proportion : 0.57 0.83 0.96 1"),side = 3,cex=1)

```
]

.pull-right[
```{r,echo=FALSE,warning =TRUE,fig.width=12,fig.height=7,message=FALSE,fig.align='center'}
screeplot(pca,col = 2:5,main = "ScreePlot",ylim =  c(0,2.5))
mtext(paste("Cumulative Proportion : 0.57 0.83 0.96 1"),side = 3,cex=1)
box()
noquote("Cum Prop. Explained: 0.57,0.83,0.96,1")
```

]

]

]



---

## 3D Plots w.r.t. first three Principal Components :

```{r,setup,echo = F,warning=FALSE}

library(rgl)
knitr::knit_hooks$set(webgl = hook_webgl)

```

.pull-middle[
```{r,echo = FALSE,test-rgl,webgl = TRUE}
color <- ifelse(My.data[,5] == 0, "deeppink1", "deepskyblue3")
pca <- prcomp(My.data[,-5],scale = T)
data_pca <- as.data.frame(cbind(pca$x, My.data[,5]))
colnames(data_pca) <- c("PC1", "PC2", "PC3", "PC4", "y")
data_pca[,5] <- ifelse(data_pca[,5] == 1, "Bankrupt", "Non Bankrupt")
data_pca[,5] <- as.factor(data_pca[,5])

plot3d(x = data_pca$PC1, y = data_pca$PC2, z = data_pca$PC3,
       col = color, xlab = "PC1", ylab = "PC2", zlab = "PC3",
       type = "s", radius = .1)
```
]
---

# LDA & QDA based on all untransformed variables :

.panelset[
.panel[.panel-name[ .red[LDA]]

.scroll-1000[

```{r,echo=T}
lda(My.data[,-5],My.data$y)
```
]

]

.panel[.panel-name[ .red[Performance]]


```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
lda_Model.8 <- MASS::lda(My.data[,-5],My.data$y,CV = T)

```

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data[,5], Predicted = predict(lda(My.data[,-5],My.data$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], lda_Model.8$class)

```
]
.panel[.panel-name[ .red[QDA]]
```{r,echo=T}
qda(My.data[,-5],My.data$y)
```

]

.panel[.panel-name[ .red[Performance]]

```{r,echo=F,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}
qda_Model.8 <- MASS::qda(My.data[,-5],My.data$y,CV = T)

```

.red[Training Set Performance]
```{r,echo=T,warning =TRUE,fig.width=6,fig.height=5.5,message=FALSE}

table(Actual = My.data[,5], Predicted = predict(qda(My.data[,-5],My.data$y))$class)

```

.red[AER Estimate (Cross Validated)]
```{r}

aer(My.data[,5], qda_Model.8$class)

```


.red[ Best till now! ]
]
]
---

class: inverse, center, middle
background-image: url("fa_cover.jpeg")
background-size: cover

#Factor Analysis
---
# Factor Analysis :

* It is used to identify the underlying structure or patterns in a set of variables and to reduce their complexity into a smaller number of factors or components. 

--

* But to proceed with factor analysis, we need to first test whether the variables are actually related. i.e, whether the Correlation matrix of the variables is an Identity matrix. 

--

* For that we will use **Bartlett Test of Sphericity**. The hypothesis is $H_0$: $R=I$ vs. $H_1:$ Not $H_0$
Where, $R$ is the population correlation matrix.          
* The test statistic is given by - 
   $$−log(det(R^*))\frac{(N−1−(2p+5))}{6}$$
Where, $R^*$ is the sample correlation matrix. $N$ is the sample size, and $p$ is the number of variables.  
It has asymptotic $\chi^2$ distribution with d.f  $\frac{p(p-1)}{2}$. It is sensitive to deviation from normality. 

---

# Factor Analysis :

.panelset[
.panel[.panel-name[ .red[Bartlett's Test]]

```{r,echo = F,warning=F,message=FALSE}
library(psych) ##bartlett test
library(GPArotation) ##factor analysis
```

* Bartlett's Test of Sphericity ! 

```{r,warning=F,echo=TRUE,message=FALSE}
cortest.bartlett(My.data_trans4[,-5])
```

.green[Thus, Bartlett's test is rejected !]

]


.panel[.panel-name[Principal Component Method]

* .green[Using Principal Component Method & Varimax Rotation :]

.scroll-1000[
```{r,echo=T,warning=FALSE}
fc <- fa((My.data_trans4[,-5]), nfactors = 2,rotate = "varimax",fm = "pa")
fc$loadings
fc$communality
```
]

]

.panel[.panel-name[ .red[Maximum Likelihood Method]]

* .green[Using Maximum Likelihood Method & Varimax Rotation :]

.scroll-1000[
```{r,echo=T,warning=FALSE}
fc_n <- fa((My.data_trans4[,-5]), nfactors = 2,rotate = "varimax", fm = "ml")
fc_n$loadings
fc_n$communality

```
]

]

.panel[.panel-name[ .red[FA Diagram]]

.pull-left[


.red[For Principle Component Method :] 

```{r,echo=F,warning=FALSE,fig.height=6}
fa.diagram(fc)

```

]

.pull-right[

.red[For Maximum Likelihood Method :]

```{r,warning=F,echo = F,fig.height=6}
fa.diagram(fc_n)
```

]
]

]

---

# Rotation Doesnot Change Fitted-Matrix :

.panelset[
.panel[.panel-name[Fitted-Matrix]

.red[Fitted Matrix with no rotation :]
```{r,echo = F}
fc_none <- fa((My.data_trans4[,-5]), nfactors = 2, rotate = "none", fm = "ml")
lamda.none <- fc_none$loadings
psi.none <- diag(fc_none$uniquenesses)
sigma.none <- lamda.none%*%t(lamda.none) + psi.none
round(sigma.none,3)

```

.red[Fitted Matrix with Varimax rotation :]
```{r,echo=F}
fc_n <- fa(My.data_trans4[,-5], nfactors = 2, rotate = "varimax", fm = "ml")
lamda.var <- fc_n$loadings
psi.var <- diag(fc_n$uniquenesses)
sigma.var <- lamda.var%*%t(lamda.var) + psi.var
round(sigma.var,3)

```

.green[Exactly Same !]

]

.panel[.panel-name[Graphical Illustration]

```{r,echo=FALSE,fig.width=10,fig.height=6,fig.align='center'}

my_fun <-function(x,main,col){
  plot(x[,1],x[,2],xlab=paste('Factor 1'),ylab=paste('Factor 2'),
       xlim=c(-1,1),ylim=c(-1,1),main=main,col=col,pch=19,cex = 1.2)
  abline(h=0,v=0)
}
par(mfrow = c(1,2))
my_fun(fc_none$loadings,main="No Rotation",col="blue")
my_fun(fc_n$loadings,main="Varimax Rotation",col="red")

```
]

]


---

class: center, middle
background-image: url("explo.jpeg")
background-size: cover
 
# Further Exploration
---

# Logistic regression :

* In LDA, QDA, we assume that **X** has mixture gaussian distribution and groupwise it has multivariate normal distribution.

--

* But in Logistic regression, we assume $X_{p\times1}$ to be non-stochastic and we model $$P_r(Y=1|x_1,x_2,...,x_p)=\frac{e^{\beta_0+\beta_1 x_1+...+\beta_p x_p}}{1 + e^{\beta_0+\beta_1 x_1+...+\beta_p x_p}}$$
Where, $\beta_0,\beta_1,...,\beta_p$ are the parameters of the model.


---

# Fitting Logistic Regression Model :

.panelset[
.panel[.panel-name[ .red[Fitted Model]]
.scroll-1000[
```{r,echo=TRUE}
Logistic_Model.10 <- glm(y ~.,data = My.data,family = binomial(link = "logit"))
summary(Logistic_Model.10)
```
]
]
.panel[.panel-name[ .red[Model Evaluation]]
.pull-bottom[
.green[Taking 0.5 as threshold value !]
]
.red[Training Set Performance]
```{r,echo= TRUE}
table(Actual= My.data$y,Predicted=ifelse(predict.glm(Logistic_Model.10,type = "response") > 0.5,1,0))
```
.red[AER Estimate(Cross Validated)]

```{r,echo=FALSE}
APER.10 <- NULL
for(i in 1:nrow(My.data)){
  Logistic_Model.i <- glm(y ~.,data = My.data[-i,],family = binomial(link = "logit"))
  APER.10[i] <- ifelse(predict(Logistic_Model.i,newdata = My.data[i,],type = "response") > 0.5,1,0)
}
APER.10 <- mean(APER.10 != My.data$y)
APER.10
```
.green[Again, we are getting 10.86% estimated AER !]
]
]

---

## Profile Analysis:

- Profile Analysis is a multivariate data analysis technique that is applicable to situations in which p treatments are administrated to two or more groups of subjects.

-  The question of equality of mean vectors is divided into several specific questions such as 

 1.Are the population profiles parallel?
 
 2.Are they coincident? (Assuming they are parallel)
 
 3.Are the profiles level? (Assuming they are  coincident)

- **Assumptions:**

 >- The test scores should have a multivariate normal distribution.
  
--

 *  .green[We can transform the data to retain multivariate normality]

--

 >- Homogeneity of the variance covariance matrix of test scores.
 
--

 *  .red[Box-M Test rejected homogeneity assumption.]

--

 >-  .blue[**So,We cannot perform Profile Analysis here !!!**]


---

# Summary : 

.pull-left[

* From EDA we have seen that, .red[CFTD, NITA and CATL are well separating bankrupt firms from financially sound firms]. From Factor analysis, we have got that these three are contributing to the first factor and CANS is contributing to the second factor.

* Also from EDA, we have seen that .red[CFTD and NITA are very highly correlated.]

* Plotting first three principal components, we visualized that .red[the data is well separated], so we applied LDA or QDA even without multivariate normality.

]

.pull-right[

* Finally, we have seen .red[QDA to the original data and Logistic regression] are yielding lowest AER(estimated)( 11% approx.).

* Further, if we only take .red[transformed NITA and CATL], then also we are not sacrificing much on AER(estimated)(13% approx.).  
]

---

class: center, middle
background-image: url("Thank.jpeg")
background-size: cover

#Thank You



